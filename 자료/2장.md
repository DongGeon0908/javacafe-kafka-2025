# JavaCafe Kafka 2025

### 메세지 == 레코드
- 카프카에서 흐르는 데이터를 의미

<br>

### 메세지, 레코드의 구성

**Key (키)**
- 레코드의 키는 메시지를 특정 파티션에 할당하는 데 사용
- 같은 키는 항상 같은 파티션에 저장 (해시 기반).
- 키는 null일 수도 있음. 이 경우 Kafka는 라운드로빈 방식으로 파티션을 선택 -> 파티션 할당에 필요함.

**Value (값)**
- 실제 전달하고자 하는 메시지 본문
- 문자열, JSON, 바이너리 등 어떤 형식 전부 가능
- Kafka는 데이터의 구조나 형식을 강제하지 않음 (하지만 보통 Avro, JSON, Protobuf 같은 포맷을 사용)

**Timestamp (타임스탬프)**
- 레코드 생성 시간
- 기본적으로 프로듀서가 설정하며, 브로커가 덮어쓸 수 있음
- Kafka는 타임스탬프 기반으로 메시지를 정렬하거나 보존 정책에 사용

**Headers (헤더) - 선택 사항**
- Kafka 0.11부터 도입된 기능으로, 메타데이터를 키-값 쌍 형태로 첨부 가능
- 메시지 자체는 변경하지 않고도 추가 정보를 담을 수 있어서, 시스템 간 연동 시 유용

<br>
<br>

### 1. 순차 처리나 파티션 지정이 필요 없는 경우
- 특정 파티션에 할당할 필요가 없을 때는 Key를 넣지 않아도 됩니다.
- Kafka는 **라운드로빈 방식**으로 자동으로 파티션을 분산시킵니다.

```json
Key: null
Value: { "message": "오늘의 공지사항입니다." }
```

### 2. 단순 로그 수집 시스템 (Log Aggregation)
- 서비스 로그 데이터를 Kafka로 수집하는 경우 Key가 필요 없는 경우가 많습니다.

```json
Key: null
Value: { "level": "INFO", "message": "Service started", "timestamp": 1679000000 }
```

<br>
<br>

### 주의할 점
- 같은 파티션 내에서만 메세지 순서 보장이 가능하기 때문에, key가 없다면 파티션이 다르게 배정될 수 있어서 순서가 섞일 수 있음.

<br>
<br>

#### Kafka - Key가 있을 때와 없을 때의 동작 처리 방식 비교

Kafka에서 **레코드(Key-Value 구조)**에서 **Key의 존재 유무에 따라 메시지가 파티션에 분배되고 처리되는 방식이 달라진다**.

---

## ✅ 1. Key가 **있는 경우**

- Kafka는 **Key를 기반으로 해시(Hashing)**를 수행하여 **지정된 파티션으로 메시지를 라우팅**합니다.
- 동일한 Key는 항상 **같은 파티션으로 보내지기 때문에 순서 보장이 가능합니다**.

### 📌 특징
- **해시 함수(hash(key)) % 파티션 수**로 파티션 선택
- **동일 Key → 동일 파티션 → 순서 보장**
- 파티션을 고정할 수 있어 **데이터 그룹핑이나 파티셔닝 처리에 유리**

### 📤 예시 동작
| Key           | Value                                | 파티션 |
|---------------|--------------------------------------|--------|
| "user123"     | { "event": "login" }                 | 1      |
| "user123"     | { "event": "logout" }                | 1      |
| "user456"     | { "event": "purchase" }              | 2      |

---

## 🚫 2. Key가 **없는 경우 (null)**

- Kafka는 Key가 없을 경우, **라운드로빈(Round-Robin)** 방식 또는 **기타 파티셔너 정책**에 따라 **임의의 파티션에 분산**합니다.
- **순서 보장 불가**: 동일한 종류의 메시지도 **다른 파티션으로 분산**될 수 있음.
- 로드 밸런싱이나 고속 병렬 처리 목적일 때 사용.

### 📌 특징
- **임의 파티션 분배**
- **메시지 순서 보장 X**
- **균등 분산으로 처리량 최적화 가능**

### 📤 예시 동작
| Key   | Value                                | 파티션 |
|-------|--------------------------------------|--------|
| null  | { "event": "login", "user": "u1" }   | 0      |
| null  | { "event": "logout", "user": "u2" }  | 2      |
| null  | { "event": "purchase", "user": "u3"} | 1      |

---

## 🔍 비교 요약

| 항목                     | Key 있음                                | Key 없음                          |
|--------------------------|------------------------------------------|-----------------------------------|
| 파티션 라우팅 방식        | Key 기반 해시                            | 라운드로빈 또는 임의 분산         |
| 메시지 순서              | Key 단위로 순서 보장                    | 순서 보장 어려움                  |
| 처리 목적                | 그룹핑, 파티션 제어, 순서 중요 처리    | 병렬 처리, 부하 분산 목적         |
| 사용 예시                | 사용자 이벤트 스트림, 트랜잭션 로그    | 시스템 로그, 센서 데이터, ETL     |

---

### 그래서 결론
- 순서 보장 필요시 key 넣기
- 순서 보장 없는 케이스의 경우, key 필요하지 않음

<br>
<br>

</hr>

### 카프카 브로커란?
> Kafka 브로커는 메시지를 저장하고, 생산자(Producer)와 소비자(Consumer) 간의 데이터를 중개하는 서버입니다. 여러 브로커가 모여 Kafka 클러스터를 구성합니다.

<br>
<br>

</hr>

### Kafka - 파티션이 3개일 때 리더 선출 방식

Kafka에서는 **각 파티션마다 "리더(Leader)" 브로커가 존재**하며, 실제 데이터의 **생산(Write) 및 소비(Read)는 리더 파티션을 통해 이루어집니다**.

---

## ✅ 기본 개념 정리

- Kafka의 **토픽(Topic)**은 **여러 파티션(Partition)**으로 구성됩니다.
- 각 파티션은 **복제(replica)**될 수 있으며, **복제본 중 하나가 "리더(Leader)"**, 나머지는 **팔로워(Follower)**가 됩니다.
- **리더는 클라이언트와 직접 통신**하며, 팔로워는 리더의 데이터를 복제만 합니다.

---

## 📌 예시: 파티션이 3개일 때

| 파티션 | 리더 브로커 | 팔로워 브로커 |
|--------|-------------|----------------|
| P0     | 브로커 1    | 브로커 2, 브로커 3 |
| P1     | 브로커 2    | 브로커 1, 브로커 3 |
| P2     | 브로커 3    | 브로커 1, 브로커 2 |

※ 이 예시는 복제 계수(replication factor)가 3일 때입니다.

---

## ⚙️ 리더 선출 방식

### 1. **초기 리더 선출**
- 토픽 생성 시 Kafka의 **파티셔너/컨트롤러 브로커**가 각 파티션의 리더를 결정합니다.
- **Round-Robin 방식** 또는 **Rack-Aware 전략** 등을 활용해 **브로커에 고르게 분산**되도록 배치합니다.

### 파티셔너/컨트롤러 브로커
- **파티셔너(Partitioner)**: Producer 측에서 메시지를 어떤 파티션에 보낼지 결정하는 로직 또는 전략입니다. (브로커가 아니라 Producer 내부의 기능입니다.)
- **컨트롤러 브로커(Controller Broker)**: Kafka 클러스터에서 파티션의 리더 선출, 브로커 상태 관리 등 클러스터를 관리하는 역할을 담당하는 브로커입니다. 클러스터 내 브로커 중 하나가 컨트롤러로 자동 선출됩니다.


### 2. **리더 장애 시 리더 재선출 (Failover)**
- 기존 리더 브로커가 장애나 다운이 되면, **팔로워 중 ISR(In-Sync Replica)**에 있는 브로커가 새로운 리더로 선출됩니다.
- **Kafka Controller 브로커**가 이 과정을 관리합니다.

> ISR = 리더와 동일한 데이터 상태를 유지하고 있는 팔로워 복제본 리스트

### 3. **선출 우선순위**
- Kafka는 ISR 목록에서 가장 먼저 준비된 복제본을 리더로 선출합니다.
- 단, Kafka 설정에 따라 **기존 리더 복구 시 다시 리더로 되돌릴 수도 있습니다** (`unclean.leader.election.enable` 설정 여부에 따라 다름).

---

## 📌 리더 선출 관련 주요 설정

| 설정 항목 | 설명 |
|------------|-----------------------------|
| `replication.factor` | 각 파티션의 복제 개수 |
| `unclean.leader.election.enable` | true일 경우, ISR 밖 복제본도 리더로 선출 가능 (데이터 유실 위험) |
| `min.insync.replicas` | ISR에 포함되어야 하는 최소 복제본 수 (생산 가능 조건) |

---

## ✅ 요약

| 항목 | 설명 |
|------|-------------------------------|
| 리더 역할 | 생산자/소비자와 직접 통신하는 주체 |
| 리더 선정 시점 | 토픽 생성 시 자동 지정 |
| 장애 처리 | ISR 내 팔로워에서 자동 선출 |
| 컨트롤러 역할 | 리더 관리 및 선출 담당 |

---

<br>
<br>

</hr>

### 토픽이란?
- Kafka에서 **토픽(Topic)**은 메시지를 분류하고 저장하는 논리적인 단위
- 메시지를 보내고 받는 통로이자 카테고리

```
예시: "user-login-events", "order-created", "system-logs" 같은 이름으로 사용됩니다.
```

- **생산자(Producer)**는 메시지를 특정 토픽으로 보냅니다.
- **소비자(Consumer)**는 원하는 토픽을 구독하여 메시지를 읽습니다.
- 하나의 토픽은 여러 개의 파티션으로 나뉘며, 파티션을 통해 확장성과 병렬처리가 가능

### Kafka에서 Zookeeper의 용도

> Kafka는 **클러스터의 메타데이터와 상태 관리를 위해 Zookeeper를 사용**

---

### ✅ Zookeeper의 주요 역할

1. **브로커 등록 및 상태 감시**
   - 클러스터 내 브로커들의 **등록/해제 및 헬스 체크**를 담당
2. **컨트롤러 선출**
   - Kafka 클러스터 내 **컨트롤러 브로커(리더 관리 역할)**를 선출
3. **토픽 및 파티션 메타데이터 관리**
   - 토픽 생성 정보, 파티션 개수, 복제본 위치 등의 **메타데이터를 저장**
4. **리더 파티션 관리**
   - 각 파티션의 **리더 정보와 ISR(In-Sync Replica) 목록**을 관리

---

## 📌 Kafka without Zookeeper?
Kafka 2.8.0부터는 **Zookeeper 없이 운영 가능한 "KRaft 모드(Kafka Raft Metadata mode)"**가 도입되어,  
향후에는 **Zookeeper가 완전히 제거될 예정**입니다.


### Zookeeper가 완전히 사장될 것인가?
- v4.x.x에서는 Zookeeper 대신 KRaft로 대체될 가능성 존재.

### 카프카의 고가용성 with 페이지 캐시

# Kafka의 페이지 캐시(Page Cache)란?

Kafka는 내부적으로 **운영체제(OS)의 페이지 캐시(Page Cache)**를 적극 활용하여 **고속 디스크 I/O를 처리**합니다.  
Kafka 자체 캐시를 쓰는 것이 아니라, **리눅스 커널의 파일 시스템 캐시**를 그대로 활용합니다.

---

## ✅ 페이지 캐시란?

- **운영체제가 디스크 파일을 읽거나 쓰면서 자주 사용하는 데이터를 메모리에 캐싱해두는 공간**입니다.
- 디스크에 접근하는 속도보다 메모리 접근 속도가 훨씬 빠르기 때문에, **디스크 I/O를 줄이고 처리 속도를 향상**시킬 수 있습니다.

---

## 📌 Kafka와 페이지 캐시의 관계

Kafka는 메시지를 파일 시스템에 저장할 때, **Java의 FileChannel + OS의 페이지 캐시를 이용한 zero-copy 방식**으로 동작합니다.

### 예시 흐름:
1. **Producer → Kafka**: 메시지 수신
2. Kafka는 데이터를 **디스크(Log Segment 파일)에 기록**
3. 이때, **운영체제는 해당 데이터를 페이지 캐시에 먼저 저장** → 디스크에는 나중에 flush
4. **Consumer가 메시지를 요청할 때**, 페이지 캐시에 이미 데이터가 있다면 **디스크를 읽지 않고 빠르게 반환**

---

## ✅ Kafka에서 페이지 캐시의 장점

| 항목 | 설명 |
|------|--------------------------|
| 고속 데이터 처리 | 디스크 직접 접근 없이 RAM에서 바로 처리 가능 |
| 높은 처리량 유지 | 수많은 메시지를 빠르게 쓰고 읽을 수 있음 |
| Zero-Copy 전송 지원 | `sendfile()` 시스템 콜을 통해 네트워크 전송 시도 |

---

## ⚠️ 주의사항

- Kafka는 데이터를 페이지 캐시에 쓴 후, 일정 시점에만 디스크에 **flush(sync)** 합니다.  
  → 시스템 장애 시 **데이터 유실 가능성** 있음 (그래서 `acks=all`, `flush.interval`, `replication` 설정이 중요함)

- 운영 중 Kafka 성능이 저하될 경우, **페이지 캐시 부족(RAM 부족)** 문제일 수 있음.  
  → **I/O wait 증가, GC 증가 등 부작용**

---

## 🔍 Kafka 관련 주요 설정 예시

| 설정 항목 | 설명 |
|-----------|----------------------------|
| `log.flush.interval.messages` | 일정 메시지 수마다 강제 flush |
| `log.flush.interval.ms`      | 일정 시간마다 flush |
| `vm.dirty_ratio`, `vm.dirty_background_ratio` | OS 페이지 캐시의 flush 타이밍 제어 (리눅스 커널 튜닝) |

---

## ✅ 정리

| 항목 | 설명 |
|------|----------------------------|
| 캐시 주체 | OS의 페이지 캐시 (Kafka 내부 캐시 아님) |
| 사용 목적 | 빠른 쓰기/읽기 성능 확보 |
| 데이터 플로우 | Kafka → OS 페이지 캐시 → 디스크 |
| 단점 | flush 타이밍에 따라 데이터 유실 가능성 있음 |

---

### 페이지 캐시?

# 운영체제의 페이지 캐시(Page Cache)란?

**페이지 캐시(Page Cache)**는 운영체제(OS)가 **디스크 파일에 접근할 때, 파일 내용을 메모리(RAM)에 저장해두는 캐시 메커니즘**입니다.

즉, **디스크에 접근하는 횟수를 줄여 속도를 빠르게 만들기 위한 메모리 기반 캐시**입니다.

---

## ✅ 왜 필요한가?

디스크(특히 HDD)는 메모리(RAM)에 비해 매우 느립니다.
- RAM: 수십 나노초(ns) 수준
- SSD: 수백 마이크로초(μs)
- HDD: 수 밀리초(ms)

따라서 자주 읽고 쓰는 데이터를 **RAM에 미리 올려놓고** 처리하면 성능이 **극적으로 향상**됩니다.

---

## 📌 페이지 캐시의 작동 원리

### 1. **읽기(Read) 시 동작**
- 응용 프로그램이 파일을 읽으려고 하면,
  - 먼저 **페이지 캐시에 해당 파일 페이지가 있는지 확인 (cache hit)**
  - 있으면 바로 RAM에서 읽음 → 매우 빠름
  - 없으면 디스크에서 읽어오고 → 페이지 캐시에 저장 → RAM에서 응답

### 2. **쓰기(Write) 시 동작**
- 응용 프로그램이 파일을 쓸 때, 실제로는 **디스크에 바로 쓰는 것이 아니라 페이지 캐시에 먼저 기록됨** → 이후 디스크로 flush
- 이런 방식은 **"write-back 캐싱"** 또는 **"deferred write"**라고 불립니다.

---

## ✅ 페이지 캐시의 장점

| 항목 | 설명 |
|------|----------------------------|
| 읽기 속도 향상 | 캐시 히트 시 디스크 접근 없이 빠르게 처리 |
| 쓰기 성능 향상 | 빠르게 캐시에 쓰고, 나중에 디스크로 저장 |
| 시스템 리소스 절약 | 동일한 파일을 여러 프로세스가 접근 시 재사용 가능 |
| 디스크 수명 향상 | 자주 쓰는 데이터의 직접 디스크 접근을 줄임 |

---

## ⚠️ 페이지 캐시의 주의사항

1. **데이터 유실 위험 (쓰기 시)**
   - 쓰기가 캐시에만 저장되고 아직 디스크에 flush되지 않은 상태에서 시스템이 꺼지면 → **데이터 유실 가능**

2. **메모리 부족 문제**
   - 페이지 캐시는 RAM을 많이 사용하므로, **메모리가 부족하면 OS가 다른 캐시를 제거하거나 디스크 스와핑이 발생**할 수 있음

3. **캐시 적중률 중요**
   - 캐시에 데이터가 없다면 **디스크 접근 → 캐시 미스(cache miss) → 성능 저하**

---

## 🔍 관련 커널 파라미터 (Linux 기준)

| 파라미터 | 설명 |
|-----------|-------------------------------|
| `vm.dirty_ratio` | RAM 중 dirty page 최대 비율 (default: 20%) |
| `vm.dirty_background_ratio` | flush 시작 비율 (default: 10%) |
| `vm.dirty_expire_centisecs` | dirty page가 오래되었을 때 flush 타이밍 |
| `vm.drop_caches` | 캐시 강제 삭제 (`echo 1 > /proc/sys/vm/drop_caches`) |

---

## ✅ 페이지 캐시 vs Buffer Cache vs Disk Cache

| 항목 | 설명 |
|------|----------------------------|
| Page Cache | 파일 읽기/쓰기 시 사용하는 캐시 (파일 시스템 수준) |
| Buffer Cache | 블록 디바이스 수준의 캐시 |
| Disk Cache | 디스크 자체의 캐시 (디스크 컨트롤러에 존재) |

※ 일반적으로 **Page Cache와 Buffer Cache는 함께 설명**되기도 하지만, 엄밀히는 다릅니다.

### JVM Heap Memory vs Page Cache 차이점

| 항목 | JVM Heap Memory | OS Page Cache |
|------|------------------|------------------|
| 위치 | **JVM 내부 메모리 공간** (Java 애플리케이션용) | **운영체제 수준의 RAM 영역** (디스크 캐시용) |
| 용도 | Java 객체 생성, GC 관리 등 애플리케이션 실행에 필요한 공간 | 디스크 I/O 성능 최적화를 위한 **파일 읽기/쓰기 캐시** |
| 관리 주체 | JVM (GC: Garbage Collector) | OS (Linux 커널이 자동 관리) |
| 데이터 종류 | Java 객체, 클래스, 배열 등 | 디스크에서 읽거나 쓴 파일 데이터 블록 |
| 캐시 지속성 | GC에 의해 주기적으로 정리됨 | 시스템에 의해 캐시되며 메모리 부족 시 제거됨 |
| 사용 예 | Kafka의 메시지 버퍼링, Map/Set 등 데이터 처리 | Kafka 로그 파일 캐싱, DB 데이터 페이지 캐싱 등 |
| 제어 방법 | JVM 옵션 (`-Xmx`, `-Xms`) | 커널 파라미터 (`vm.dirty_ratio`, `drop_caches`) |

### 결론.
-> 더 로우한 레벨에서 캐싱 처리에 대한 작업을 지원.

---

# Kafka의 로그(Log)란?

Kafka에서 **"로그(Log)"는 메시지를 디스크에 저장하는 구조화된 파일 시스템입니다.**  
각 파티션(Partition)은 **자신만의 로그 파일(Log)**을 갖고, 이 로그는 **메시지를 순차적으로 저장**합니다.

즉, **Kafka는 메시지를 로그 형태로 디스크에 저장하고, 컨슈머는 이 로그를 읽어가며 처리**합니다.

---

## ✅ Kafka 로그의 구조

1. **토픽(Topic)** → 여러 **파티션(Partition)**으로 나뉨
2. **각 파티션은 고유의 로그(Log) 파일을 가짐**
3. 이 로그는 다시 여러 **로그 세그먼트(Log Segment)**로 분할되어 저장됨

## 📌 로그 세그먼트(Log Segment)

- Kafka는 로그 파일을 일정 크기나 시간 단위로 분할해서 저장합니다.
- 각각의 세그먼트 파일은 **일련번호 기반으로 구분되며, 메시지를 순서대로 저장**합니다.
- **세그먼트가 꽉 차면 새 파일을 생성하고 이어서 기록**합니다.

| 파일 이름 | 설명 |
|-----------|-------------------------|
| `.log` | 실제 메시지 데이터 저장 |
| `.index` | 메시지 오프셋 → 파일 위치 매핑 |
| `.timeindex` | 타임스탬프 → 오프셋 매핑 |

---

## ✅ 로그의 장점 (Kafka가 로그 구조를 쓰는 이유)

| 항목 | 설명 |
|------|------------------------------|
| 순차쓰기 | 디스크에 **순차적으로만 쓰기 → 고속 I/O** |
| 데이터 유지 | 컨슈머가 읽은 후에도 **데이터를 지우지 않음**, 설정된 보존기간까지 유지 |
| 오프셋 기반 읽기 | 컨슈머가 **원하는 위치(오프셋)**부터 읽을 수 있음 |
| 분산 저장 | 각 파티션 별로 분리되어 **병렬 저장/처리 가능**

---

## 🔧 로그 관련 Kafka 설정 예시

| 설정 항목 | 설명 |
|-----------|--------------------------|
| `log.retention.hours` | 메시지를 보존할 시간 (기본: 168시간 = 7일) |
| `log.retention.bytes` | 파티션별 로그 최대 크기 초과 시 삭제 |
| `log.segment.bytes` | 세그먼트 파일 크기 (기본: 1GB) |
| `log.cleaner.enable` | 컴팩션(Log Compaction) 기능 활성화 여부 |

---

## ✅ 로그 삭제/압축 정책

Kafka는 로그 파일이 무한정 쌓이는 것을 방지하기 위해 **2가지 방식으로 오래된 데이터를 정리**합니다:

### 1. **시간/용량 기반 삭제 (Time-based Retention)**
- 오래된 세그먼트를 자동으로 삭제

### 2. **로그 컴팩션(Log Compaction)**
- **Key 기반 최신 Value만 유지**, 오래된 Value는 제거
- 예: 상태 저장 시스템에서 유용

---

## ✅ Kafka 로그는 메시지 저장소다!

Kafka에서 로그는 단순한 기록이 아니라,  
> **"컨슈머가 메시지를 읽을 수 있는 메시지 저장소"**입니다.

컨슈머는 로그의 특정 오프셋부터 계속 읽어가며 메시지를 소비하고,  
로그는 설정된 기간 동안 계속 유지됩니다.

### 결론
-> 결국. 카프카 로그는 메세지의 history를 저장하는 것.

---

# Kafka Streams란?

**Kafka Streams**는 Apache Kafka에서 제공하는 **경량 스트림 처리 라이브러리**입니다.  
Kafka에 저장된 데이터를 실시간으로 **처리, 변환, 집계, 결합, 분석**할 수 있도록 도와줍니다.

> ✅ 특징: Kafka Streams는 별도 서버 없이 **Java 애플리케이션 내에서 직접 실행**됩니다.

---

## ✅ Kafka Streams의 핵심 특징

| 항목 | 설명 |
|------|----------------------------|
| 분산 처리 | Kafka 파티션 기반으로 자동 병렬 처리 |
| 서버리스 | 별도 클러스터 필요 없음 → 애플리케이션 내에서 실행 |
| 상태 저장(Stateful) | 집계, 조인, 윈도우 처리 등을 위해 로컬 상태 저장소 사용 |
| 정확성 보장 | at-least-once (기본), exactly-once도 지원 |
| 통합성 | Kafka, KTable, KStream 등 Kafka 자체와 자연스럽게 통합됨 |

---

## 📌 주요 개념

### 1. **KStream**
- **연속적인 레코드 스트림 (event stream)**  
- 예: 주문 생성 이벤트, 로그인 이벤트 등

### 2. **KTable**
- **Key-Value 형태의 상태 저장 테이블 (State Table)**  
- 가장 최신 상태를 나타냄  
- 예: 사용자 프로필 상태, 마지막 주문 내역

### 3. **GlobalKTable**
- 전체 노드에 복제되는 테이블 (Broadcast된 KTable)

### 4. **State Store**
- 윈도우 집계, 조인 등을 위한 로컬 상태 저장소

---

# Kafka Streams의 동작 원리

Kafka Streams는 Kafka 토픽에 저장된 데이터를 **애플리케이션 내에서 실시간 처리**하기 위한 고수준 라이브러리입니다.  
주요 구성 요소들은 Kafka 토픽 → KStream/KTable → 처리 연산 → 출력 토픽 흐름으로 작동합니다.

---

## ✅ 1. 입력 데이터 수신 (Kafka → KStream/KTable)

Kafka Streams 애플리케이션은 Kafka Consumer API 기반으로 **지정된 토픽에서 데이터를 읽고**,  
이를 **KStream(이벤트 스트림)** 또는 **KTable(상태 테이블)** 형태로 표현합니다.

```text
Kafka Topic → KStream/KTable

---
